<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  

<meta name="author" content="Jon-Paul Cavallaro" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="pmwg-sampler-and-signal-detection-theory.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Particle Based Sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#computational-requirements"><i class="fa fa-check"></i><b>1.1</b> Computational Requirements</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.2</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#why-would-you-use-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.3</b> Why would you use Particle Metropolis within Gibbs Sampling</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#the-hierarhcical-structure-assumed"><i class="fa fa-check"></i><b>1.4</b> The Hierarhcical Structure Assumed</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-particle-metropolis-within-gibbs-sampling-provides"><i class="fa fa-check"></i><b>1.5</b> What Particle Metropolis within Gibbs Sampling provides</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#what-is-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.6</b> What is Particle Metropolis within Gibbs Sampling?</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#how-do-we-generate-proposals-in-pmwg-sampling-using-particle-metropolis"><i class="fa fa-check"></i><b>1.7</b> How do we generate proposals in PMwG sampling using Particle Metropolis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> PMwG sampler and Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#writing-a-log-likelihood-function"><i class="fa fa-check"></i><b>2.0.2</b> Writing a log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdt-log-likelihood-function-for-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2</b> SDT log likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#computation-time-of-log-likelihood-function"><i class="fa fa-check"></i><b>2.2.2</b> Computation time of log likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#pmwg-framework"><i class="fa fa-check"></i><b>2.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="2.3.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>2.3.1</b> Model start points</a></li>
<li class="chapter" data-level="2.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#run-sdtsampler"><i class="fa fa-check"></i><b>2.3.2</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#check-sampling-process"><i class="fa fa-check"></i><b>2.4</b> Check sampling process</a></li>
<li class="chapter" data-level="2.5" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#simulating-posterior-data"><i class="fa fa-check"></i><b>2.5</b> Simulating posterior data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html"><i class="fa fa-check"></i><b>3</b> PMwG sampler and sequential sampling models</a><ul>
<li class="chapter" data-level="3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#description-of-forstmann-experiment"><i class="fa fa-check"></i><b>3.1</b> Description of Forstmann experiment</a></li>
<li class="chapter" data-level="3.2" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#setting-up-the-sampler"><i class="fa fa-check"></i><b>3.2</b> Setting up the sampler</a></li>
<li class="chapter" data-level="3.3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#writing-the-lba-log-likelihood-function"><i class="fa fa-check"></i><b>3.3</b> Writing the LBA log likelihood function</a><ul>
<li class="chapter" data-level="3.3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#trialwise-lba-log-likelihood-function"><i class="fa fa-check"></i><b>3.3.1</b> Trialwise LBA log likelihood function</a></li>
<li class="chapter" data-level="3.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>3.3.2</b> Model start points</a></li>
<li class="chapter" data-level="3.3.3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#run-sampler"><i class="fa fa-check"></i><b>3.3.3</b> Running the sampler</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="example-2-single-threshold-parameter.html"><a href="example-2-single-threshold-parameter.html"><i class="fa fa-check"></i><b>4</b> Example 2 - Single threshold parameter</a></li>
<li class="chapter" data-level="5" data-path="example-3-wagenmakers-2008-experiment-2.html"><a href="example-3-wagenmakers-2008-experiment-2.html"><i class="fa fa-check"></i><b>5</b> Example 3 - Wagenmakers (2008) Experiment 2</a></li>
<li class="chapter" data-level="6" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html"><i class="fa fa-check"></i><b>6</b> Common Problems (Better name required) Troubleshooting page</a><ul>
<li class="chapter" data-level="6.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#how-to-write-a-log-likelihood-function"><i class="fa fa-check"></i><b>6.1</b> How to write a log likelihood function</a><ul>
<li class="chapter" data-level="6.1.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1.1</b> Writing your log likelihood function: Tips, errors and check list</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-rtchoice-example.html"><a href="non-rtchoice-example.html"><i class="fa fa-check"></i><b>7</b> Non RT/Choice example</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Particle Based Samplers for MCMC</h1>
<p class="author"><em>Jon-Paul Cavallaro</em></p>
<p class="date"><em>Monday 20 July 2020</em></p>
</div>
<div id="introduction-to-particle-based-sampler-for-mcmc" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction to Particle Based Sampler for MCMC</h1>
<p>Contains implementations of particle based sampling methods for model parameter estimation. Primarily an implementation of the Particle Metropolis within Gibbs sampler outlined in the paper available at <a href="https://arxiv.org/abs/1806.10089" class="uri">https://arxiv.org/abs/1806.10089</a>, it also contains code for covariance estimation and time varying models.</p>
<div id="computational-requirements" class="section level2">
<h2><span class="header-section-number">1.1</span> Computational Requirements</h2>
<ul>
<li>R Version</li>
<li>Packages</li>
<li>Memory</li>
<li>Document computational requirements - memory 200mb</li>
<li>Minutes</li>
<li>Size of samples</li>
<li>Memory required</li>
<li>Can it be done on a grid or laptop</li>
</ul>
</div>
<div id="assumed-knowledge" class="section level2">
<h2><span class="header-section-number">1.2</span> Assumed knowledge</h2>
<p>This tutorial and introduction assumes you are familiar hierarchical Bayesian estimation and MCMC sampling. If you would like to read more on this, please see Shiffrin, Lee, Kim, and Wagenmakers (2008) <a href="https://onlinelibrary.wiley.com/doi/full/10.1080/03640210802414826">tutorial on Hierachical Bayesian Methods</a> and van Ravenzwaaij, Cassey, and Brown’s (2018) <a href="https://link.springer.com/article/10.3758/s13423-016-1015-8?wt_mc=Other.Other.8.CON1172.PSBR%20VSI%20Art09">introduction to Markov Chain Monte-Carlo Sampling</a>.</p>
</div>
<div id="why-would-you-use-particle-metropolis-within-gibbs-sampling" class="section level2">
<h2><span class="header-section-number">1.3</span> Why would you use Particle Metropolis within Gibbs Sampling</h2>
<p>This software is intended to help estimate models in a hierarchical structure with random effects for subjects. You will need to be able to write a function that evaluates the density of one subject’s data, given values for that subject’s parameters (i.e. their random effects). Everything else is taken care of by the sampler functions. The model that defines the density for of an individual subject’s data could be a linear regression for example, or simple cognitive models like Signal Detection models (which is one of the examples we provide in this tutorial), or models that can be very challenging to estimate, such as the Linear Ballistic Accumulator (LBA) or Diffusion model. As long as you have a model for which you can provide a likelihood, this software will help estimate the model in a hierarchical Bayesian way.</p>
<p>Benefits of the Particle Metropolis within Gibbs sampling algorithm include:</p>
<ul>
<li><p>It allows you to efficiently get posterior samples from difficult-to-estimate models with highly correlated parameters, such as the LBA or diffusion model, and these samples have nice properties (e.g., lower autocorrelation than other MCMC samplers).</p></li>
<li><p>Statistical efficiency makes it feasilbe to draw a large number of posterior samples. This can be important in posterior inference, for example in calculating Bayes Factors using established methods.</p></li>
<li><p>It allows you to estimate the covariance structure between parameters in a principled manner.</p></li>
</ul>
</div>
<div id="the-hierarhcical-structure-assumed" class="section level2">
<h2><span class="header-section-number">1.4</span> The Hierarhcical Structure Assumed</h2>
<p>The PMwG package is very flexible in that it is agnostic about the data-level model; it allows the user to specify the model that defines the density of each subject’s data. However, the package makes fixed assumptions about the hierarchical structure across participants. The package assumes a multivariate normal random effects structure. For example, when estimating an LBA model, each participant will have several parameters, such as a start point (A), threshold (b), drift rate (v), and non-decision time (t0). The PMwG package assumes that the vector of each subject’s parameter value follows a group-level distribution which is multivariate normal. The algorithm will estimate the group-level mean for each parameter, as well as its variance, and also the correlations between parameters in the sample.</p>
<p>One consequence of the multivariate normal assumption is that all parameters are assumed to be unbounded (i.e. able to take values anywhere on the real line). Cognitive models often have bounded parameters (e.g. in the LBA model, the non-decision time parameter cannot be negative, as it represents a length of time). The user should deal with bounded parameters by transforming them to be unbounded. We give examples of that, in the likelihood functions.</p>
</div>
<div id="what-particle-metropolis-within-gibbs-sampling-provides" class="section level2">
<h2><span class="header-section-number">1.5</span> What Particle Metropolis within Gibbs Sampling provides</h2>
<p>The sampler will provide samples from the posterior distribution of the model in three categories:</p>
<ul>
<li><p>The means for the group level parameters (<code>theta</code>).</p></li>
<li><p>The vectors of random effects for each subject (individual level parameter values, <code>alpha</code>)</p></li>
<li><p>The group-level variance covariance matrix (<code>sigma</code>).</p></li>
</ul>
</div>
<div id="what-is-particle-metropolis-within-gibbs-sampling" class="section level2">
<h2><span class="header-section-number">1.6</span> What is Particle Metropolis within Gibbs Sampling?</h2>
<p>There are two sampling approaches incorporated into PMwG. One is the well-established and easy to apply Gibbs sampling on the group-level parameters. Gibbs sampling is very powerful and efficient, and it can work for the group-level parameters because the package assumes a multivariate normal distribution, which is easy to work with.</p>
<p>However, for the subject-level parameters (random effects), Gibbs sampling is not possible; at least for most cognitive models. For this reason, the PMwG package uses particle methods to sample random effects. Particle sampling works like other Markov chain samplers, such as Metropolis-Hastings. At each step, the sample (the vector of random effects) from the previous step is compared to a large number of proposals (“particles”). The new sample is chosen from amongst the particles (including the previous sample), according to how well they match the data and the prior.</p>
<p>The key to making the algorithm efficient is to propose particles carefully. Our algorithm uses adaptive proposal distributions, individually tuned for each participant, to make sure that good proposal particles are generated without requiring a prohibitively large number of particles in total. How often the sampler accepts a new particle (as opposed the previous sample) is referred to as the acceptance rate. Acceptance rate can be adjusted for maximum efficiency (somewhere around 30-50% acceptance is great) by changing the total number of particles and by changing the variance of the proposal distribution (parameter “epsilon”). The particles are evaluated in a parallel way, which helps speed computation.</p>
</div>
<div id="how-do-we-generate-proposals-in-pmwg-sampling-using-particle-metropolis" class="section level2">
<h2><span class="header-section-number">1.7</span> How do we generate proposals in PMwG sampling using Particle Metropolis</h2>
<p>PMwG has three sampling stages. The first stage is called <code>burn-in</code>, the second <code>adaptation</code>, and the third is referred to as the <code>sampled</code> stage. The stages emploiy different numbers of particles, and different proposal distributions. This makes the algorithm most efficient.</p>
<p><b>(include trace plot with ab lines separating these stages) </b></p>
<p>In the <code>burn-in</code> and <code>adaptation stages</code>, the proposals (or random effects vectors) for each subject are sampled from a mixture of two sources. One source is the group-level distribution and the second source is a multivariate normal distribution centred on the current best guess for the subject’s random effects vector (alpha), with a variance that is smaller than the group level distribution. We generate proposals from both sources, because proposals generated from the group level distribution act as a safety net in situations where proposals generated from the subject’s current alpha are unusual or unlikely. If this occurs instead of the sampler taking a long way to return a sensible vector of random effects, a group level proposal will instead be chosen, leading to a faster sampling time.</p>
<p>One thing we want to know is the posterior distribution for each subject’s random effects (alpha). For this reason, we throw away samples from the burn-in stage, because this is a period in which the sampler is trying to work its way away from an initial guess, and stabilise on samples which are from the true posterior distribution for each subjects random effects.</p>
<p>In the <code>adaptation stage</code>, we continue the algorithm used in the burn-in stage until we collect a minimum of 20 unique samples from each subject’s posterior. These samples are used to give a good idea of what the posterior distribution looks like for each subject’s random effects vector. That allows us to build an adaptive proposal distribution that makes very efficient proposals, in the next stage.</p>
<p>In the final <code>sampling</code> stage, we calculate generate a multivariate normal distribution (referred to as the adaptive proposal distribution), that summarises the unique samples in the adaptation stage, and uses this to generate future proposals. An important feature of this distribution is that, for each subject, it summarises not only the posterior distribution of their random effects but also the way these random effects relate to the group-level parameter. This allows us to draw conditional proposals: proposals which are both consistent with that subject’s random effects and with the current proposal for the group-level distribution. Because of this, the proposals generated are frequently accepted, meaning we can lower the number of particles needed in this stage (for example, 20 instead of 200), and still maintain an adequate acceptance rate. Further, we continue to update this proposal distribution throughout the sampling stage so we have a more accurate proposal distribution.</p>
<p>As a safety precaution during the sampling stage, we also include a few proposal particles from the same algorithm as used in the burn-in stage. This protects against very poor conditional proposal distributions.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="pmwg-sampler-and-signal-detection-theory.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
