<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  

<meta name="author" content="Jon-Paul Cavallaro" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pmwg-sampler-and-signal-detection-theory.html"/>
<link rel="next" href="example-2-single-threshold-parameter.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Particle Based Sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#computational-requirements"><i class="fa fa-check"></i><b>1.1</b> Computational Requirements</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.2</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#why-would-you-use-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.3</b> Why would you use Particle Metropolis within Gibbs Sampling</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#the-hierarchical-structure-assumed"><i class="fa fa-check"></i><b>1.4</b> The Hierarchical Structure Assumed</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-particle-metropolis-within-gibbs-sampling-provides"><i class="fa fa-check"></i><b>1.5</b> What Particle Metropolis within Gibbs Sampling provides</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#what-is-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.6</b> What is Particle Metropolis within Gibbs Sampling?</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#how-do-we-generate-proposals-in-pmwg-sampling-using-particle-metropolis"><i class="fa fa-check"></i><b>1.7</b> How do we generate proposals in PMwG sampling using Particle Metropolis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> PMwG sampler and Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#writing-a-log-likelihood-function"><i class="fa fa-check"></i><b>2.0.2</b> Writing a log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log-likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdt-log-likelihood-function-for-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2</b> SDT log-likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#computation-time-of-log-likelihood-function"><i class="fa fa-check"></i><b>2.2.2</b> Computation time of log-likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#pmwg-framework"><i class="fa fa-check"></i><b>2.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="2.3.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>2.3.1</b> Model start points</a></li>
<li class="chapter" data-level="2.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#run-sdtsampler"><i class="fa fa-check"></i><b>2.3.2</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#check-sampling-process"><i class="fa fa-check"></i><b>2.4</b> Check sampling process</a></li>
<li class="chapter" data-level="2.5" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#simulating-posterior-data"><i class="fa fa-check"></i><b>2.5</b> Simulating posterior data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html"><i class="fa fa-check"></i><b>3</b> PMwG sampler and sequential sampling models</a><ul>
<li class="chapter" data-level="3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#description-of-forstmann-experiment"><i class="fa fa-check"></i><b>3.1</b> Description of Forstmann experiment</a></li>
<li class="chapter" data-level="3.2" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#linear-ballistic-accumulator-parameters"><i class="fa fa-check"></i><b>3.2</b> Linear Ballistic Accumulator Parameters</a></li>
<li class="chapter" data-level="3.3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#writing-the-log-likelihood-function"><i class="fa fa-check"></i><b>3.3</b> Writing the log-likelihood function</a><ul>
<li class="chapter" data-level="3.3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#trialwise-lba-log-likelihood-function"><i class="fa fa-check"></i><b>3.3.1</b> Trialwise LBA log-likelihood function</a></li>
<li class="chapter" data-level="3.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>3.3.2</b> Model start points</a></li>
<li class="chapter" data-level="3.3.3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#run-sampler"><i class="fa fa-check"></i><b>3.3.3</b> Running the sampler</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="example-2-single-threshold-parameter.html"><a href="example-2-single-threshold-parameter.html"><i class="fa fa-check"></i><b>4</b> Example 2 - Single threshold parameter</a></li>
<li class="chapter" data-level="5" data-path="example-3-wagenmakers-2008-experiment-2.html"><a href="example-3-wagenmakers-2008-experiment-2.html"><i class="fa fa-check"></i><b>5</b> Example 3 - Wagenmakers (2008) Experiment 2</a></li>
<li class="chapter" data-level="6" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html"><i class="fa fa-check"></i><b>6</b> Common Problems (Better name required) Troubleshooting page</a><ul>
<li class="chapter" data-level="6.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#how-to-write-a-log-likelihood-function"><i class="fa fa-check"></i><b>6.1</b> How to write a log likelihood function</a><ul>
<li class="chapter" data-level="6.1.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1.1</b> Writing your log likelihood function: Tips, errors and check list</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-rtchoice-example.html"><a href="non-rtchoice-example.html"><i class="fa fa-check"></i><b>7</b> Non RT/Choice example</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pmwg-sampler-and-sequential-sampling-models" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> PMwG sampler and sequential sampling models</h1>
<p>In this chapter we’ll demonstrate how to use the PMwG sampler with a sequential sampling model; the Linear Ballistic Accumulator (LBA). Please ensure the pmwg package is installed. We currently recommended installing pmwg via devtools.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The pmwg package will be on CRAN - this step will be removed.</span>
<span class="kw">install_github</span>(<span class="st">&#39;newcastlecl\pmwg&#39;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pmwg)</code></pre></div>
<div id="description-of-forstmann-experiment" class="section level2">
<h2><span class="header-section-number">3.1</span> Description of Forstmann experiment</h2>
<p>Forstmann et al looked at neural correlates of decision making under time pressure, with an aim to identify areas of the brain associated with speed-accuracy tradeoff. Imaging (fMRI) and behavioural data was collected; however, we will analyse behavioural data from the decision-making task only. In terms of modelling the data, Forstmann expected to find differences in thresholds (direction?) for each of the three speed-emphasis conditions. We have included the Forstmann et als data in the pmwg package as a data frame object named <code>forstmann</code>. The sampler requires a data frame with a <b><code>subject</code></b> column. The subject column data type can be a factor or numeric.</p>
<p>Table <a href="pmwg-sampler-and-sequential-sampling-models.html#tab:forsthead10">3.1</a> shows the first ten trials from the Forstmann dataset. Participants <code>(n = 19)</code> were asked to indicate whether a cloud of dots in a random-dot kinematogram (RDK) moved to the left or the right of the screen. The IV was a within-subject, speed-accuracy manipulation where, before each trial began, pariticipants were instructed to make their choice <i>accurately</i> <code>(condition = 1)</code>, with <i>urgency</i><code>(condition = 3)</code>or were presented with a <i>neutral</i> message <code>(condition = 2)</code>. Stimuli were either <i>left</i> <code>(stim = 1)</code> or <i>right</i> <code>(stim =2)</code> and responses <i>left</i> <code>(resp = 1)</code> or <i>right</i> <code>(resp =2)</code>. Response times <code>(rt)</code> were recorded in seconds. For more information about the design of the experiment please see <a href="https://www.pnas.org/content/105/45/17538.short">the original paper</a>.</p>
<table>
<caption><span id="tab:forsthead10">Table 3.1: </span>First 10 trials in Forstmann dataset. The <code>forstmann</code> dataset is an object/data frame</caption>
<thead>
<tr class="header">
<th align="center">subject</th>
<th align="center">condition</th>
<th align="center">stim</th>
<th align="center">resp</th>
<th align="center">rt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4319</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.5015</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3104</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4809</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3415</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3465</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3572</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4042</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3866</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.3683</td>
</tr>
</tbody>
</table>
</div>
<div id="linear-ballistic-accumulator-parameters" class="section level2">
<h2><span class="header-section-number">3.2</span> Linear Ballistic Accumulator Parameters</h2>
<p>There are preliminary steps we need to complete before running the sampler. Let’s begin by defining the Linear Ballistic Accumulator (LBA) <span class="citation">(Brown and Heathcote <a href="#ref-brown2008simplest">2008</a>)</span> model parameters.</p>
<ul>
<li><code>b</code> threshold parameter (the evidence required to make a response)</li>
<li><code>v</code> is drift rate or average speed of evidence accumulation</li>
<li><code>A</code> is the model’s start point</li>
<li><code>t0</code> is non-decision time</li>
<li><code>sv</code> is the standard deviation of drift rate</li>
</ul>
<p>Now we know the LBA model parameters, we can create a vector of model parameter names, which we’ll use in our log-likelihood function. You can name this object as you wish; however, in our example, we will call it <code>pars</code>. The number of parameters and the parameter names you include in the <code>pars</code> vector <b>must</b> match those included in your log-likelihood function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;b1&quot;</span>, <span class="st">&quot;b2&quot;</span>, <span class="st">&quot;b3&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;v1&quot;</span>, <span class="st">&quot;v2&quot;</span>, <span class="st">&quot;t0&quot;</span>)</code></pre></div>
<p>For the Forstmann dataset, we need three threshold parameters (<code>b1</code>, <code>b2</code>, and <code>b3</code> i.e. one for each condition) because we assume response caution differs for each verbal instruction. We include two drift rate parameters: <code>v1</code> for the incorrect accumulator and <code>v2</code> for the correct accumulator, a start point parameter <code>A</code> and a non-decision time <code>t0</code> parameter. We’ve made a decision to set the <code>sv</code> to 1 to satisfy the scaling properties of the model. We haven’t included the <code>sv</code> parameter in the <code>pars</code> vector, however it is found in the LBA’s likelihood function below.</p>
<p>Next we create a <code>priors</code> object; a list that contains two components <b> Do we need to explain what priors are and why we do this?</b></p>
<ul>
<li><code>start_mu</code> a vector containing the prior for model parameter means</li>
<li><code>start_sig</code> the prior covariance matrix for model parameters.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">priors &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">start_mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(pars)),
  <span class="dt">start_sig =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(pars)))
)</code></pre></div>
<p>The <code>priors</code> object in our example is initiated with zeros. <b>Under what conditions would this priors object differ?</b></p>
</div>
<div id="writing-the-log-likelihood-function" class="section level2">
<h2><span class="header-section-number">3.3</span> Writing the log-likelihood function</h2>
<p>Just as we did with the SDT example, we’ll write a slow and a fast log likelihood function. The runtime difference is caused by calling the <code>dLBA</code> function line-by-line for the slow log likelihood and calling the <code>dLBA</code> function once for all the data in the fast log likelihood function. When writing a new log likelihood function, we suggest starting with a slow, line-by-line function for easier debugging.</p>
<p>The LBA log-likelihood function takes three arguments:</p>
<ul>
<li><code>x</code> is a named parameter vector (e.g. <code>pars</code>)</li>
<li><code>data</code> is your data set (e.g.<code>forstmann</code>). Your dataset must include a <code>&quot;subject&quot;</code> column</li>
<li><code>sample = FALSE</code> calculates a density function or <code>TRUE</code> generates a posterior, predictive sample that matches the shape of data.</li>
</ul>
<p>The log likelihood function shown below includes functions from the <code>rtdists</code> package for generating data and estimating density. If you’d like to run through this example, it is best to copy the <code>tw_lba_ll</code> function from the code block below rather than copying from the following separate code chunks, as some curly braces have been removed from code chunks.</p>
<p>NOTE: This version of a loglikelihood is very slow and inneficient because rLBA and dLBA will be called on each line of the data. This will result in very slow sampling times and is a consequence of the rtdists package, not an issue with the PMwG sampling speed. We recommend people who have experience writing log likelihood write a faster version, or use the faster version we have created “HERE”, however this method is easier for people new to modelling, and is less likely to result in mistakes.</p>
<div id="trialwise-lba-log-likelihood-function" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Trialwise LBA log-likelihood function</h3>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">tw_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A &lt;-<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b &lt;-<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc &lt;-<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve &lt;-<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 &lt;-<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs &lt;-<span class="st"> </span><span class="kw">c</span>(vc, ve)
    } <span class="cf">else</span> {
      vs &lt;-<span class="st"> </span><span class="kw">c</span>(ve, vc)
    }
    
    <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
      
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> b,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
                     )
      }
  }
  
  <span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">pmax</span>(out, <span class="fl">1e-10</span>)))
    <span class="kw">return</span>(out)
  }
}</code></pre></td></tr></table></div>
<p>The first line in the trialwise LBA log-likelihood function (Line 2 below) takes the exponent of the parameter values to move all parameter values to the real line. <b>The purpose of this is to….. </b> Line 3 and 4 then checks RTs are faster than the non-decision time parameter, and zeroes those RTs that are faster than non-decision time.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">tw_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }</code></pre></td></tr></table></div>
<!-- Next (Line 7) we create a vector `bs` containing threshold parameters for each row (i.e. each choice) in the data set that takes into account the condition and adds the start point value. We add the start point parameter `A` value to each threshold parameter so that threshold is greater than the start point value.  -->
<!-- ``` {r lbaLL2, attr.source='.numberLines startFrom="7"', echo=TRUE, eval=FALSE} -->
<!--   bs <- x["A"] + x[c("b1", "b2", "b3")][data$condition] -->
<!-- ``` -->
<p>At line 7 <code>sample = TRUE</code> we create an empty vector <code>tmp</code> that will contain values sampled from the posterior distribution. Then we remove all responses <code>resp</code> and response times <code>rt</code> from the <code>data</code> object. This readies the <code>data</code> object for the posterior predictive data. If <code>sample = FALSE</code> (the else statement from line 11) we initiate an <code>out</code> vector with a length equal to the number of rows in the dataset, where likelihood values for each subject and condition will be stored.</p>
<div class="sourceCode" startFrom="7"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>7
8
9
10
11
12
13
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>,<span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>,<span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }</code></pre></td></tr></table></div>
<p>Next, we use a <code>for</code> loop to estimate the model parameter values (x) of each parameter for each choice or row in the data set, so that any conditional parameters (for example ‘b’ in our model) are correctly assigned.</p>
<p>conditional just means that when condition = (for example) “speed” (which is condition 3), then the “b” for that row will be assigned “b.3”.</p>
<p>Riley example - Next, we use a <code>for</code> loop to assign the proposed parameter values (x) to the corresponding row in the data set,. By doing this any conditional parameters (for example ‘b’ in our model) are assigned to the correct rows (for example, values for b.3 are assigned to rows where the condition was 3)</p>
<p>For example, we want to calculate the density for a model that has three threshold parameters (one for each condition; 1 = Accuracy, 2 = neutral, or 3 = speed emphasis). In the loop, we paste ‘b.’ to the condition in row [i] and add ‘A’ (the start point - we do this to ensure the threshold is greater than the starting point).</p>
<p>Next on line we ensure the correct ordering of our drift rate parameters. Recall that for data$stim, 1 = a left response. Therefore, when stimulus = 1 (left), the correct accumulator (vc) is the first accumulator – so we order the vs; (vc,ve). The else statement gives the opposite for right moving stimuli (stimulus = 2), the incorrect accumulator (ve) is the first accumulator, so the vs order is (ve,vc). This ensures that the matching correct and error drift rates line up with the stimulus for that condition.</p>
<div class="sourceCode" startFrom="15"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
    } <span class="cf">else</span> {
      vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
    }</code></pre></td></tr></table></div>
<p>The <code>if else</code> statement below (Line 9-32) does one of two things: <code>if (sample)</code> calculates the posterior predictive data and the <code>else</code> statement calculates the density function. Toward the end of the <code>else</code> statment (line 28) we take all implausible likelihood values, assign them to the <code>bad</code> object and set them to zero. The final line in the <code>else</code> statement takes the log of all likelihood values, sums them and then assigns the model’s log-likelihood value to the <code>out</code> variable.</p>
<div class="sourceCode" startFrom="9"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
    out &lt;-<span class="st"> </span>rtdists<span class="op">::</span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="kw">nrow</span>(data),
                         <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                         <span class="dt">b =</span> bs,
                         <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                         <span class="dt">mean_v =</span> x[<span class="kw">c</span>(<span class="st">&quot;v1&quot;</span>, <span class="st">&quot;v2&quot;</span>)],
                         <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                         <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                         <span class="dt">silent =</span> <span class="ot">TRUE</span>)
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span>rtdists<span class="op">::</span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt,
                         <span class="dt">response =</span> data<span class="op">$</span>correct,
                         <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                         <span class="dt">b =</span> bs,
                         <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                         <span class="dt">mean_v =</span> x[<span class="kw">c</span>(<span class="st">&quot;v1&quot;</span>, <span class="st">&quot;v2&quot;</span>)],
                         <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                         <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                         <span class="dt">silent =</span> <span class="ot">TRUE</span>)
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
  }
  out</code></pre></td></tr></table></div>
<p>The next step is to include your log-likelihood function. This must be called before you create the sampler object in the following step. You can load your log-likelihood function from an external script:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="dt">file =</span> <span class="st">&quot;yourLogLikelihoodFile.R&quot;</span>)</code></pre></div>
<p>Once you’ve setup your parameters, priors and your log-likelihood function, the next step is to initialise the <code>sampler</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">pmwgs</span>(
  <span class="dt">data =</span> forstmann,
  <span class="dt">pars =</span> pars,
  <span class="dt">prior =</span> priors,
  <span class="dt">ll_func =</span> lba_loglike
)</code></pre></div>
<p>The <code>pmwgs</code> function takes a set of arguments (listed below) and returns a list containing the required components for performing the particle metropolis within Gibbs steps.</p>
<ul>
<li><code>data =</code> your data - a data frame (e.g.<code>forstmann</code>) with a column for participants called <b><code>subject</code></b></li>
<li><code>pars =</code> the model parameters to be used (e.g.<code>pars</code>)</li>
<li><code>prior =</code> the priors to be used (e.g.<code>priors</code>)</li>
<li><code>ll_func =</code> name of log-likelihood function you’ve sourced above (e.g.<code>lba_loglike</code>)</li>
</ul>
</div>
<div id="start-points" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Model start points</h3>
<p>You have the option to set model start points. We have specified sensible start points for the Forstmann dataset. If you chose not to specify start points, the sampler will randomly sample points from the prior distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start_points &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">mu =</span> <span class="kw">c</span>(.<span class="dv">2</span>, .<span class="dv">2</span>, .<span class="dv">2</span>, .<span class="dv">4</span>, .<span class="dv">3</span>, <span class="fl">1.3</span>, <span class="op">-</span><span class="dv">2</span>),
  <span class="dt">sig2 =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(.<span class="dv">01</span>, <span class="kw">length</span>(pars)))
)</code></pre></div>
<p>The <code>start_points</code> object contains two vectors:</p>
<ul>
<li><code>mu</code> a vector of start points for the mu of each model parameter</li>
<li><code>sig2</code> vector containing the start points of the covariance matrix of covariance between model parameters.</li>
</ul>
</div>
<div id="run-sampler" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Running the sampler</h3>
<p>Okay - now we are ready to run the sampler.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">init</span>(sampler, <span class="dt">theta_mu =</span> start_points<span class="op">$</span>mu,
                <span class="dt">theta_sig =</span> start_points<span class="op">$</span>sig2)</code></pre></div>
<p>Here we are using the <code>init</code> function to generate initial start points for the random effects and storing them in the <code>sampler</code> object. First we pass the <code>sampler</code> object from above that includes our data, parameters, priors and log-likelihood function. If we decided to specify our own start points (as above), we would include the <code>theta_mu</code> and <code>theta_sig</code> arguments.</p>
<p>Now we can run the sampler using the <code>run_stage</code> function. The <code>run_stage</code> function takes four arguments:</p>
<ul>
<li><code>x</code> the <code>sampler</code> object including parameters</li>
<li><code>stage =</code> the sampling stage (e.g. <code>&quot;burn&quot;</code>, <code>&quot;adapt&quot;</code> or <code>&quot;sample&quot;</code>)</li>
<li><code>iter =</code> is the number of iterations for the sampling stage</li>
<li><code>particles =</code> is the number of particles generated on each iteration</li>
</ul>
<p>It is optional to include the <code>iter =</code> and <code>particles =</code> arguments. If these are not included, <code>iter</code> and <code>particles</code> default to 1000. The number of iterations you choose for your burn in stage is similar to choices made when running deMCMC, however, this varies depending on the time the model takes to reach the ‘real’ posterior space.</p>
<p>First we run our burn in stage by setting <code>stage =</code> to <code>&quot;burn&quot;</code>. Here we have set iterations to be 500, which may take some time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">burned &lt;-<span class="st"> </span><span class="kw">run_stage</span>(sampler, <span class="dt">stage =</span> <span class="st">&quot;burn&quot;</span>, <span class="dt">iter =</span> <span class="dv">500</span>, <span class="dt">particles =</span> <span class="dv">1000</span>)</code></pre></div>
<p>Now we run our adaptation stage by setting <code>stage = &quot;adapt&quot;</code> Because we have not specified number of iterations or particles, the sampler will use the default value of 1000 for each of these arguments. N.B. The sampler will quit adaptation stage after 20 unique values have been accepted for each subject. This means adaptation may not use all 1000 iterations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adapted &lt;-<span class="st"> </span><span class="kw">run_stage</span>(burned, <span class="dt">stage =</span> <span class="st">&quot;adapt&quot;</span>)</code></pre></div>
<p>At the start of the <code>sampled</code> stage, the sampler object will create a ‘proposal’ distribution for each subject’s random effects using a conditional multi-variate normal. This proposal distribution is then used to efficiently generate new particles for each subject which means we can reduce the number of particles on each iteration whilst still achieving acceptance rates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampled &lt;-<span class="st"> </span><span class="kw">run_stage</span>(adapted, <span class="dt">stage =</span> <span class="st">&quot;sample&quot;</span>, <span class="dt">iter =</span> <span class="dv">100</span>, <span class="dt">particles =</span> <span class="dv">100</span>)</code></pre></div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-brown2008simplest">
<p>Brown, Scott, and Andrew Heathcote. 2008. “The Simplest Complete Model of Choice Response Time: Linear Ballistic Accumulation.” <em>Cognitive Psychology</em> 57 (3). Elsevier: 153–78.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pmwg-sampler-and-signal-detection-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="example-2-single-threshold-parameter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
