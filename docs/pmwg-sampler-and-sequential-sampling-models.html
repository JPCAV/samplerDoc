<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 PMwG sampler and sequential sampling models | Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  

<meta name="author" content="Jon-Paul Cavallaro" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pmwg-sampler-and-signal-detection-theory.html"/>
<link rel="next" href="example-2-single-threshold-parameter.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Particle Based Sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#computational-requirements"><i class="fa fa-check"></i><b>1.1</b> Computational Requirements</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.2</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#why-would-you-use-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.3</b> Why would you use Particle Metropolis within Gibbs Sampling</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#the-hierarchical-structure-assumed"><i class="fa fa-check"></i><b>1.4</b> The Hierarchical Structure Assumed</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#what-particle-metropolis-within-gibbs-sampling-provides"><i class="fa fa-check"></i><b>1.5</b> What Particle Metropolis within Gibbs Sampling provides</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#what-is-particle-metropolis-within-gibbs-sampling"><i class="fa fa-check"></i><b>1.6</b> What is Particle Metropolis within Gibbs Sampling?</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#how-do-we-generate-proposals-in-pmwg-sampling-using-particle-metropolis"><i class="fa fa-check"></i><b>1.7</b> How do we generate proposals in PMwG sampling using Particle Metropolis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> PMwG sampler and Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#writing-a-log-likelihood-function"><i class="fa fa-check"></i><b>2.0.2</b> Writing a log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log-likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdt-log-likelihood-function-for-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2</b> SDT log-likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
<li class="chapter" data-level="2.2.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#computation-time-of-log-likelihood-function"><i class="fa fa-check"></i><b>2.2.2</b> Computation time of log-likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#sdtPMwG"><i class="fa fa-check"></i><b>2.3</b> PMwG Framework</a><ul>
<li class="chapter" data-level="2.3.1" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#start-points"><i class="fa fa-check"></i><b>2.3.1</b> Model start points</a></li>
<li class="chapter" data-level="2.3.2" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#run-sdtsampler"><i class="fa fa-check"></i><b>2.3.2</b> Running the sampler</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#check-sampling-process"><i class="fa fa-check"></i><b>2.4</b> Check sampling process</a></li>
<li class="chapter" data-level="2.5" data-path="pmwg-sampler-and-signal-detection-theory.html"><a href="pmwg-sampler-and-signal-detection-theory.html#simulating-posterior-data"><i class="fa fa-check"></i><b>2.5</b> Simulating posterior data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html"><i class="fa fa-check"></i><b>3</b> PMwG sampler and sequential sampling models</a><ul>
<li class="chapter" data-level="3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#description-of-forstmann-experiment"><i class="fa fa-check"></i><b>3.1</b> Description of Forstmann experiment</a></li>
<li class="chapter" data-level="3.2" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#linear-ballistic-accumulator-parameters"><i class="fa fa-check"></i><b>3.2</b> Linear Ballistic Accumulator Parameters</a></li>
<li class="chapter" data-level="3.3" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#writing-the-log-likelihood-function"><i class="fa fa-check"></i><b>3.3</b> Writing the log-likelihood function</a><ul>
<li class="chapter" data-level="3.3.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#fstLBALL"><i class="fa fa-check"></i><b>3.3.1</b> Fast LBA Log-likelihood Function</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#pmwg-framework"><i class="fa fa-check"></i><b>3.4</b> PMwG Framework</a><ul>
<li class="chapter" data-level="3.4.1" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#lbaStartPts"><i class="fa fa-check"></i><b>3.4.1</b> Model start points</a></li>
<li class="chapter" data-level="3.4.2" data-path="pmwg-sampler-and-sequential-sampling-models.html"><a href="pmwg-sampler-and-sequential-sampling-models.html#run-sampler"><i class="fa fa-check"></i><b>3.4.2</b> Running the sampler</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="example-2-single-threshold-parameter.html"><a href="example-2-single-threshold-parameter.html"><i class="fa fa-check"></i><b>4</b> Example 2 - Single threshold parameter</a></li>
<li class="chapter" data-level="5" data-path="example-3-wagenmakers-2008-experiment-2.html"><a href="example-3-wagenmakers-2008-experiment-2.html"><i class="fa fa-check"></i><b>5</b> Example 3 - Wagenmakers (2008) Experiment 2</a></li>
<li class="chapter" data-level="6" data-path="troubleshoot.html"><a href="troubleshoot.html"><i class="fa fa-check"></i><b>6</b> Common Problems (Better name required) Troubleshooting page</a><ul>
<li class="chapter" data-level="6.1" data-path="troubleshoot.html"><a href="troubleshoot.html#how-to-write-a-log-likelihood-function"><i class="fa fa-check"></i><b>6.1</b> How to write a log likelihood function</a><ul>
<li class="chapter" data-level="6.1.1" data-path="troubleshoot.html"><a href="troubleshoot.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1.1</b> Writing your log likelihood function: Tips, errors and check list</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-rtchoice-example.html"><a href="non-rtchoice-example.html"><i class="fa fa-check"></i><b>7</b> Non RT/Choice example</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pmwg-sampler-and-sequential-sampling-models" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> PMwG sampler and sequential sampling models</h1>
<p>In this chapter we’ll demonstrate how to use the PMwG sampler with a sequential sampling model; the Linear Ballistic Accumulator (LBA). Please ensure the <code>PMwG</code> and <code>rtdists</code> packages are installed. We currently recommended installing <code>PMwG</code> via devtools.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The pmwg package will be on CRAN - this step will be removed.</span>
<span class="kw">install_github</span>(<span class="st">&#39;newcastlecl\pmwg&#39;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pmwg)</code></pre></div>
<div id="description-of-forstmann-experiment" class="section level2">
<h2><span class="header-section-number">3.1</span> Description of Forstmann experiment</h2>
<p>Forstmann et al looked at neural correlates of decision making under time pressure, with an aim to identify areas of the brain associated with speed-accuracy tradeoff. Imaging (fMRI) and behavioural data was collected; however, we will analyse behavioural data from the decision-making task only. In terms of modelling the data, Forstmann expected to find differences in thresholds (direction?) for each of the three speed-emphasis conditions. We have included the Forstmann et als data in the <code>PMwG</code> package as a data frame named <code>forstmann</code>. The sampler requires a data frame with a <b><code>subject</code></b> column. The subject column data type can be a factor or numeric.</p>
<p>Table <a href="pmwg-sampler-and-sequential-sampling-models.html#tab:forsthead10">3.1</a> shows the first ten trials from the Forstmann dataset. Participants <code>(n = 19)</code> were asked to indicate whether a cloud of dots in a random-dot kinematogram (RDK) moved to the left or the right of the screen. The IV was a within-subject, speed-accuracy manipulation where, before each trial began, pariticipants were instructed to make their choice <i>accurately</i> <code>(condition = 1)</code>, with <i>urgency</i><code>(condition = 3)</code>or were presented with a <i>neutral</i> message <code>(condition = 2)</code>. Stimuli moved either <i>left</i> <code>(stim = 1)</code> or <i>right</i> <code>(stim = 2)</code> and responses were <i>left</i> <code>(resp = 1)</code> or <i>right</i> <code>(resp = 2)</code>. Response times <code>(rt)</code> were recorded in seconds. For more information about the design of the experiment please see <a href="https://www.pnas.org/content/105/45/17538.short">the original paper</a>.</p>
<table>
<caption><span id="tab:forsthead10">Table 3.1: </span>First 10 trials in Forstmann dataset. The <code>forstmann</code> dataset is an object/data frame</caption>
<thead>
<tr class="header">
<th align="center">subject</th>
<th align="center">condition</th>
<th align="center">stim</th>
<th align="center">resp</th>
<th align="center">rt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4319</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.5015</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3104</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4809</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3415</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3465</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3572</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.4042</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.3866</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">0.3683</td>
</tr>
</tbody>
</table>
</div>
<div id="linear-ballistic-accumulator-parameters" class="section level2">
<h2><span class="header-section-number">3.2</span> Linear Ballistic Accumulator Parameters</h2>
<p>There are preliminary steps we need to complete before running the sampler. Let’s begin by defining the Linear Ballistic Accumulator (LBA) <span class="citation">(Brown and Heathcote <a href="#ref-brown2008simplest">2008</a>)</span> model parameters.</p>
<ul>
<li><code>b</code> threshold parameter (the evidence required to trigger a response)</li>
<li><code>v</code> is drift rate or average speed of evidence accumulation</li>
<li><code>A</code> is the model’s start point</li>
<li><code>t0</code> is non-decision time</li>
<li><code>sv</code> is the standard deviation of drift rate</li>
</ul>
</div>
<div id="writing-the-log-likelihood-function" class="section level2">
<h2><span class="header-section-number">3.3</span> Writing the log-likelihood function</h2>
<p>Just as we did with the SDT example, we’ll write a slow and a fast log-likelihood function. The runtime difference is caused by calling the <code>dLBA</code> function line-by-line for the slow log-likelihood and calling the <code>dLBA</code> function once for all the data in the fast log-likelihood function. When writing a new log-likelihood function, we suggest starting with a slow, line-by-line function for easier debugging.</p>
<p>The LBA log-likelihood function takes three arguments:</p>
<ul>
<li><code>x</code> is a named parameter vector (e.g. <code>pars</code>)</li>
<li><code>data</code> is your dataset (e.g.<code>forstmann</code>). Your dataset must include a <code>&quot;subject&quot;</code> column</li>
<li><code>sample = FALSE</code> calculates a density function or <code>TRUE</code> generates a posterior, predictive sample that matches the shape of data.</li>
</ul>
<p>The log-likelihood function shown below includes functions from the <code>rtdists</code> package for generating data and estimating density. If you’d like to run through this example, it is best to copy the <code>tw_lba_ll</code> function from the code block below rather than copying from the separate code chunks where curly braces have been removed.</p>
<p>NOTE: The trialwise log-likelihood is very slow and inneficient because <code>rLBA</code> and <code>dLBA</code> will be called on each line of the data. This will result in very slow sampling times and is a consequence of the <code>rtdists</code> package, not an issue with the PMwG sampling speed. If you have experience writing log-likelihoods, we recommend writing a faster version than our trialwise function, or use the fast log-likelihood we have written in section <a href="pmwg-sampler-and-sequential-sampling-models.html#fstLBALL">3.3.1</a>. If you are new to modelling, we recommend trying the trialwise (slow) log-likelihood function as it is easier to follow, troubleshoot and is less likely to result in errors.</p>
<p>Let’s begin by installing <code>rtdists</code> package…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rtdists)</code></pre></div>
<p>and now our complete trialwise (slow) log-likelihood function.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">tw_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  
  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
      } <span class="cf">else</span> {
      vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
      }
    
    <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> b,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
      )
      }
  }
  
<span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }
}</code></pre></td></tr></table></div>
<p>The first line in the <code>tw_lba_ll</code> function (Line 2 below) takes the exponent of the parameter values. We do this as the LBA expects values on the real number line. Line 3 and 4 then checks RTs are faster than the non-decision time parameter <code>t0</code>, and return a low value, indicating that the given value of <code>t0</code> is not likely.</p>
<div class="sourceCode" startFrom="2"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>2
3
4
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)</code></pre></td></tr></table></div>
<p>Now we create a vector with values sampled from the posterior distribution OR estimating the density. If <code>sample = TRUE</code>, we remove all responses <code>(resp)</code> and rts. This means when we return <code>data</code>, we are returning the posterior predictive data which matches with the associated <code>subject</code> and <code>condition</code>.</p>
<p>If <code>sample = FALSE</code> (the <code>else</code> statement from line 11) we create an <code>out</code> vector, with a length equal to the number of rows in the dataset, and store the likelihood value for each subject and condition.</p>
<div class="sourceCode" startFrom="7"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>7
8
9
10
11
12
13
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
    tmp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }</code></pre></td></tr></table></div>
<p>Next, we loop over rows in the dataset. In this <code>for</code> loop, we find the values <code>(x)</code> of each parameter in our model for each row, so that any conditional parameters (for example <code>b</code> in our model) are correctly assigned. For example, we want to calculate the density for a model that has three threshold parameters (one for each condition; <code>1  = accuracy</code>, <code>2 = neutral</code>, or <code>3 = speed</code>). In the loop, we paste <code>b.</code> to the condition in row <code>[i]</code> and add <code>A</code> (the start point - we do this to ensure the threshold is greater than the starting point).</p>
<p>On line 22 we set the order of our drift rate parameters. Recall that <code>stim = 1</code> is a stimulus moving to the left. <code>dLBA</code> requires the drift accumulators to be matched i.e. when <code>data$stim[i] == 1</code>, the drift rate for the correct accumulator <code>(vc)</code> is in position one, so we order the drift rates; <code>vs = c(vc, ve)</code>. The <code>else</code> statement addresses right moving stimuli <code>data$stim[i] == 2</code>, the incorrect accumulator <code>(ve)</code> is the first accumulator, so the drift rate parameter order is <code>vs = c(ve, vc)</code>. This ensures that the correct <code>(vc)</code> and error <code>(ve)</code> drift rates match with the corresponding accumulators for given stimuli.</p>
<div class="sourceCode" startFrom="15"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
    A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
    b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
    vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
    ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
    t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
    s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
    <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
      vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
    } <span class="cf">else</span> {
      vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
    }</code></pre></td></tr></table></div>
<p>The following section calls the relevant <code>rtdists</code> function depending on whether we are sampling from the posterior <code>(rLBA)</code> or estimating the density <code>(dLBA)</code>. We then input the parameters from above (using the names set above) into the relevant function. When generating data from the posterior (Line 30-37), <code>rLBA</code> is called for each line of the data, storing the generated <code>rt</code> and <code>response</code> given the posterior parameter estimates in the <code>tmp</code> vector (which we then reassign to the empty <code>data$rt</code> and <code>data$resp</code> columns). We set <code>n = 1</code>, since we are calling <code>rLBA</code> on 1 row of the data. When estimating the density (Line 42 to 50), dLBA is called for each line of the data, storing the probability of the <code>rt</code> and <code>response</code> under the proposed parameters <code>(x)</code> in the <code>out</code> vector.</p>
<div class="sourceCode" startFrom="29"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample) {
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    } <span class="cf">else</span> {
      out[i] &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt[i],
                     <span class="dt">response =</span> data<span class="op">$</span>resp[i],
                     <span class="dt">A =</span> A,
                     <span class="dt">b =</span> b,
                     <span class="dt">mean_v =</span> vs,
                     <span class="dt">sd_v =</span> s,
                     <span class="dt">t0 =</span> t0,
                     <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                     <span class="dt">silent =</span> <span class="ot">TRUE</span>
      )
      }</code></pre></td></tr></table></div>
<p>This final section tells the function what to return; <code>data</code> - when sampling posterior predictive (Line 56) - or the sum of the likelihoods - when estimating density (Line x - y). On line 58 we take all implausible likelihood values, assign them to the <code>bad</code> object and then (line 59) set them to zero. The final two lines within the <code>else</code> statement take the log of all likelihood values, sums them, assigns the model’s log-likelihood value to the <code>out</code> variable and returns that value.</p>
<div class="sourceCode" startFrom="55"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>55
56
57
58
59
60
61
62
</pre></td><td class="sourceCode"><pre><code class="sourceCode r"><span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }</code></pre></td></tr></table></div>
<div id="fstLBALL" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Fast LBA Log-likelihood Function</h3>
<p>As the data is large, and the <code>dLBA</code> function takes some time to run, the log-likelihood code above is computationally inefficient. There are several ways to improve the log-likelihood’s performance; in our example below, we reduce the number of calls to <code>dLBA</code> (and <code>rLBA</code> when sampling) to one call. We do this by passing a list of <code>dLBA</code> parameter values for the length of the data.</p>
<p><b>NOTE:</b> When generating posterior predictive data, the <code>rLBA</code> function is still executed for each row of data; however, it is only executed several times, so computational efficiency is uncompromised.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fast_lba_ll &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {
  x &lt;-<span class="st"> </span><span class="kw">exp</span>(x)
  <span class="cf">if</span> (<span class="kw">any</span>(data<span class="op">$</span>rt <span class="op">&lt;</span><span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>])) {
    <span class="kw">return</span>(<span class="op">-</span><span class="fl">1e10</span>)
  }
  <span class="cf">if</span> (sample) {
    data<span class="op">$</span>rt &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
    data<span class="op">$</span>resp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">nrow</span>(data))
  } <span class="cf">else</span> {
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  <span class="cf">if</span> (sample) {
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)) {
      A =<span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
      b =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, data<span class="op">$</span>condition[i])] <span class="op">+</span><span class="st"> </span>A
      vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
      ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
      t0 =<span class="st"> </span>x[<span class="st">&quot;t0&quot;</span>]
      s =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)
      <span class="cf">if</span> (data<span class="op">$</span>stim[i] <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
        vs =<span class="st"> </span><span class="kw">c</span>(vc, ve)
      } <span class="cf">else</span> {
        vs =<span class="st"> </span><span class="kw">c</span>(ve, vc)
      }
      
      tmp &lt;-<span class="st"> </span><span class="kw">rLBA</span>(<span class="dt">n =</span> <span class="dv">1</span>,
                  <span class="dt">A =</span> A,
                  <span class="dt">b =</span> b,
                  <span class="dt">mean_v =</span> vs,
                  <span class="dt">sd_v =</span> s,
                  <span class="dt">t0 =</span> t0,
                  <span class="dt">dist =</span> <span class="st">&quot;norm&quot;</span>,
                  <span class="dt">silent =</span> <span class="ot">TRUE</span>
                  )
      data<span class="op">$</span>rt[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>rt
      data<span class="op">$</span>resp[i] &lt;-<span class="st"> </span>tmp<span class="op">$</span>resp
    }
  } <span class="cf">else</span> {
    all_b &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    vlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;v.1&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)), 
                 <span class="st">&quot;v.2&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data)))
    stim &lt;-<span class="st"> </span><span class="kw">levels</span>(data<span class="op">$</span>stim)
    con &lt;-<span class="st"> </span><span class="kw">levels</span>(data<span class="op">$</span>condition)
    
    <span class="cf">for</span> (c <span class="cf">in</span> con) {
      <span class="cf">for</span> (s <span class="cf">in</span> stim) {
        use &lt;-<span class="st"> </span>data<span class="op">$</span>condition <span class="op">==</span><span class="st"> </span>c <span class="op">&amp;</span><span class="st"> </span>data<span class="op">$</span>stim <span class="op">==</span><span class="st"> </span>s
        <span class="cf">if</span> (<span class="kw">any</span>(use)) {
          bs =<span class="st"> </span>x[<span class="kw">paste0</span>(<span class="st">&quot;b.&quot;</span>, c)] <span class="op">+</span><span class="st"> </span>x[<span class="st">&quot;A&quot;</span>]
          all_b[use] =<span class="st"> </span>bs
          vc =<span class="st"> </span>x[<span class="st">&quot;vc&quot;</span>]
          ve =<span class="st"> </span>x[<span class="st">&quot;ve&quot;</span>]
          <span class="cf">if</span> (s <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
            vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>vc
            vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>ve
          } <span class="cf">else</span> {
            vlist<span class="op">$</span>v.<span class="dv">1</span>[use] =<span class="st"> </span>ve
            vlist<span class="op">$</span>v.<span class="dv">2</span>[use] =<span class="st"> </span>vc
          }
        }
      }
    }
    
    out &lt;-<span class="st"> </span><span class="kw">dLBA</span>(<span class="dt">rt =</span> data<span class="op">$</span>rt,
                <span class="dt">response =</span> data<span class="op">$</span>resp,
                <span class="dt">A =</span> x[<span class="st">&quot;A&quot;</span>],
                <span class="dt">b =</span>  all_b,
                <span class="dt">mean_v =</span> vlist,
                <span class="dt">sd_v =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                <span class="dt">t0 =</span> x[<span class="st">&quot;t0&quot;</span>],
                <span class="dt">distribution =</span> <span class="st">&quot;norm&quot;</span>,
                <span class="dt">silent =</span> <span class="ot">TRUE</span>
    )
    }
  
  <span class="cf">if</span> (sample) {
    <span class="kw">return</span>(data)
  } <span class="cf">else</span> {
    bad &lt;-<span class="st"> </span>(out <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-10</span>) <span class="op">|</span><span class="st"> </span>(<span class="op">!</span><span class="kw">is.finite</span>(out))
    out[bad] &lt;-<span class="st"> </span><span class="fl">1e-10</span>
    out &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(out))
    <span class="kw">return</span>(out)
  }
}</code></pre></div>
<p>You should improve your log-likelihood’s performance as you see fit. When you’re confident that your log-likelihood code functions correctly, we suggest saving it as a separate script so it can be sourced and loaded when running the sampler. If you’re learning how to write log-likelihood functions, take a look at our <a href="troubleshoot.html#troubleshoot">troubleshooting section</a> for tips.</p>
</div>
</div>
<div id="pmwg-framework" class="section level2">
<h2><span class="header-section-number">3.4</span> PMwG Framework</h2>
<p>Now that we have a log-likelihood function, we can set up the <code>PMwG</code> sampler. Running the sampler follows the same procedure outlined in the <a href="pmwg-sampler-and-signal-detection-theory.html#sdtPMwG">SDT chapter</a>; we need to set up a vector of model parameter names, create a <code>priors</code> object, source our LBA log-likelihood script and then create our <code>sampler</code> object.</p>
<p>Let’s begin by creating a vector of model parameter names, which we’ll use in our log-likelihood function. You can name this object as you wish; however, in our example, we name it <code>pars</code>. <br><b>IMPORTANT NOTE:</B> The parameters you list in the <code>pars</code> vector <b>must</b> match those included in your log-likelihood function i.e. they must have the same names and the same number of parameters.</p>
<p>For the <code>forstmann</code> dataset, we use three threshold parameters (one <code>b</code> for each condition) because we assume that the condition has an effect on level of caution. We include two drift rate parameters: <code>v1</code> for the incorrect accumulator and <code>v2</code> for the correct accumulator, a start point parameter <code>A</code> and a non-decision time <code>t0</code> parameter.</p>
<p>We’ve made a decision to set the <code>sv</code> to 1 to satisfy the scaling properties of the model. As such, we haven’t included the <code>sv</code> parameter in the <code>pars</code> vector - it is found in the LBA’s log-likelihood function (see above).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;b1&quot;</span>, <span class="st">&quot;b2&quot;</span>, <span class="st">&quot;b3&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;v1&quot;</span>, <span class="st">&quot;v2&quot;</span>, <span class="st">&quot;t0&quot;</span>)</code></pre></div>
<p>Next we create our <code>priors</code> object; a list that contains two components:</p>
<ul>
<li><code>theta_mu_mean</code> a vector containing the prior for model parameter means</li>
<li><code>theta_mu_var</code> the prior covariance matrix for model parameters.</li>
</ul>
<p><b>The <code>theta_mu_mean</code> object is initiated with zeros, and the covariance has the diagonal of 1 and 0’s for the off diagonal. We use generic priors here which are broad. This means that the prior is <b>blah</b> and the covariance matrix posterior space is able to be explored. In some examples, the prior will need to be adjusted to account for different factors or priors we already know. </b></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">priors &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">theta_mu_mean =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(pars)),
  <span class="dt">theat_mu_var =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(pars)))
)</code></pre></div>
<p>Now source and load your log-likelihood script <i>before</i> you create the sampler object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="dt">file =</span> <span class="st">&quot;fast_lba_ll.R&quot;</span>)</code></pre></div>
<p>Next we specify the PMwG <code>sampler</code> object. The <code>pmwgs</code> function takes a set of arguments (listed below) and returns a list containing the required components for performing the particle metropolis within Gibbs steps.</p>
<ul>
<li><code>data =</code> your data - a data frame (e.g.<code>forstmann</code>) with a column for participants called <b><code>subject</code></b></li>
<li><code>pars =</code> the model parameters to be used (e.g.<code>pars</code>)</li>
<li><code>prior =</code> the priors to be used (e.g.<code>priors</code>)</li>
<li><code>ll_func =</code> name of log-likelihood function to be used (e.g.<code>fast_lba_ll</code>)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">pmwgs</span>(<span class="dt">data =</span> data,
                 <span class="dt">pars =</span> pars,
                 <span class="dt">prior =</span> priors,
                 <span class="dt">ll_func =</span> fast_lba_ll
                 )</code></pre></div>
<div id="lbaStartPts" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Model start points</h3>
<p>There is also an option to set model start points. We have specified sensible start points for the <code>forstmann</code> dataset under the LBA model. If you choose not to specify start points, the sampler will randomly sample points from the prior distribution.</p>
<p>The <code>start_points</code> object contains two vectors:</p>
<ul>
<li><code>mu</code> a vector of start points for the mu of each model parameter</li>
<li><code>sig2</code> vector containing the start points of the covariance matrix of covariance between model parameters.</li>
</ul>
<p>NOTE: Start points must be on the real line. Our log-likelihood function immediately takes the exponent of these start points and returns only positive values, so we use the log of sensible start points here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">start_points &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">mu =</span> <span class="kw">c</span>(<span class="kw">log</span>(<span class="fl">1.2</span>),
         <span class="kw">log</span>(<span class="fl">1.2</span>), 
         <span class="kw">log</span>(<span class="fl">1.2</span>),
         <span class="kw">log</span>(<span class="fl">1.4</span>),
         <span class="kw">log</span>(<span class="fl">1.3</span>),
         <span class="kw">log</span>(<span class="fl">3.5</span>),
         <span class="kw">log</span>(<span class="fl">0.13</span>)),
  <span class="dt">sig2 =</span> <span class="kw">diag</span>(<span class="kw">rep</span>(.<span class="dv">01</span>,
                  <span class="kw">length</span>(pars)))
)</code></pre></div>
</div>
<div id="run-sampler" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Running the sampler</h3>
<p>Setup is now complete and we can run the sampler. First, we use the <code>init</code> function to generate initial start points for the random effects and store them in the <code>sampler</code> object. Here we specify start points by providing values for the <code>start_mu</code> and <code>start_sig</code> arguments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sampler &lt;-<span class="st"> </span><span class="kw">init</span>(sampler, 
                <span class="dt">start_mu =</span> start_points<span class="op">$</span>mu,
                <span class="dt">start_sig =</span> start_points<span class="op">$</span>sig2)</code></pre></div>
<p>To run the sampler, we use the <code>run_stage</code> function. The <code>run_stage</code> function takes four arguments:</p>
<p>REQUIRED - PMWGS AND STAGE, OTHERS ARE OPTIONAL</p>
<ul>
<li><code>pmwgs =</code> the <code>sampler</code> object including parameters that was created from the <code>init</code> function above.</li>
<li><code>stage =</code> the sampling stage (These are:<code>&quot;burn&quot;</code>, <code>&quot;adapt&quot;</code> or <code>&quot;sample&quot;</code> - in this order).</li>
<li><code>iter =</code> is the number of iterations for the sampling stage. This is similar to running deMCMC, where it takes many iterations to reach the posterior space. Default = 1000.</li>
<li><code>particles =</code> is the number of particles generated on each iteration. Default = 1000.</li>
<li><code>epsilon =</code> is a value between 0 and 1 which reduces the size of the sampling space. We use lower values of epsilon when there are more parameters to estimate. Default = 1.</li>
<li><code>n_cores =</code> the number of cores on a machine you wish to use to run the sampler. This allows sampling to be run across cores (parallelising for subjects). Default = 1.</li>
</ul>
<p>The first sampling stage to run is ‘burn in’, so we set the stage argument to (<code>&quot;burn&quot;</code>) and assign the outcome to a variable called <code>burned</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">burned &lt;-<span class="st"> </span><span class="kw">run_stage</span>(sampler, 
                    <span class="dt">stage =</span> <span class="st">&quot;burn&quot;</span>,
                    <span class="dt">iter =</span> <span class="dv">500</span>,
                    <span class="dt">particles =</span> <span class="dv">2000</span>,
                    <span class="dt">epsilon =</span> .<span class="dv">5</span>)</code></pre></div>
<p>Next we run the adaptation stage by setting <code>stage = &quot;adapt&quot;</code>. The sampler will automatically exit the adapt stage when it has enough unique samples to create a multivariate normal ‘proposal’ distribution for each subject’s random effects. So we set iterations <code>iter =</code> to a high number, as it should exit before reaching this point. If it doesn’t, there is likely an issue with acceptance rates, the likelihood function or limited data to operate on (i.e. few trials in some conditions).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">adapted &lt;-<span class="st"> </span><span class="kw">run_stage</span>(burned, 
                     <span class="dt">stage =</span> <span class="st">&quot;adapt&quot;</span>, 
                     <span class="dt">iter =</span> <span class="dv">10000</span>, 
                     <span class="dt">particles =</span> <span class="dv">2000</span>,
                     <span class="dt">epsilon =</span> .<span class="dv">5</span>)</code></pre></div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-brown2008simplest">
<p>Brown, Scott, and Andrew Heathcote. 2008. “The Simplest Complete Model of Choice Response Time: Linear Ballistic Accumulation.” <em>Cognitive Psychology</em> 57 (3). Elsevier: 153–78.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pmwg-sampler-and-signal-detection-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="example-2-single-threshold-parameter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
