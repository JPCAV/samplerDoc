<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 How to use the PMwG sampler - Signal Detection Theory | Particle Based Samplers for MCMC</title>
  <meta name="description" content="Particle Based Sampler for MCMC" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 How to use the PMwG sampler - Signal Detection Theory | Particle Based Samplers for MCMC" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Particle Based Sampler for MCMC" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 How to use the PMwG sampler - Signal Detection Theory | Particle Based Samplers for MCMC" />
  
  <meta name="twitter:description" content="Particle Based Sampler for MCMC" />
  

<meta name="author" content="Jon-Paul Cavallaro" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="example-2-forstmann-et-al-2008-dataset.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PMwG Samplers Package</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Particle Based Sampler for MCMC</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#assumed-knowledge"><i class="fa fa-check"></i><b>1.1</b> Assumed knowledge</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#computational-requirements"><i class="fa fa-check"></i><b>1.2</b> Computational Requirements</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#background-information"><i class="fa fa-check"></i><b>1.3</b> Background information</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><i class="fa fa-check"></i><b>2</b> How to use the PMwG sampler - Signal Detection Theory</a><ul>
<li class="chapter" data-level="2.0.1" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#sdtOutline"><i class="fa fa-check"></i><b>2.0.1</b> Signal Detection Theory analysis of lexical decision task</a></li>
<li class="chapter" data-level="2.0.2" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#writing-a-log-likelihood-function"><i class="fa fa-check"></i><b>2.0.2</b> Writing a log-likelihood function</a></li>
<li class="chapter" data-level="2.1" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#testing-the-sdt-log-likelihood-function"><i class="fa fa-check"></i><b>2.1</b> Testing the SDT log likelihood function</a></li>
<li class="chapter" data-level="2.2" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#sdt-log-likelihood-function-for-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2</b> SDT log likelihood function for Wagenmakers experiment</a><ul>
<li class="chapter" data-level="2.2.1" data-path="how-to-use-the-pmwg-sampler-signal-detection-theory.html"><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#description-of-wagenmakers-experiment"><i class="fa fa-check"></i><b>2.2.1</b> Description of Wagenmakers experiment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="example-2-forstmann-et-al-2008-dataset.html"><a href="example-2-forstmann-et-al-2008-dataset.html"><i class="fa fa-check"></i><b>3</b> Example 2 - Forstmann et al. (2008) dataset</a><ul>
<li class="chapter" data-level="3.1" data-path="example-2-forstmann-et-al-2008-dataset.html"><a href="example-2-forstmann-et-al-2008-dataset.html#description-of-forstmann-experiment"><i class="fa fa-check"></i><b>3.1</b> Description of Forstmann experiment</a></li>
<li class="chapter" data-level="3.2" data-path="example-2-forstmann-et-al-2008-dataset.html"><a href="example-2-forstmann-et-al-2008-dataset.html#setting-up-the-sampler"><i class="fa fa-check"></i><b>3.2</b> Setting up the sampler</a><ul>
<li class="chapter" data-level="3.2.1" data-path="example-2-forstmann-et-al-2008-dataset.html"><a href="example-2-forstmann-et-al-2008-dataset.html#start-points"><i class="fa fa-check"></i><b>3.2.1</b> Model start points</a></li>
<li class="chapter" data-level="3.2.2" data-path="example-2-forstmann-et-al-2008-dataset.html"><a href="example-2-forstmann-et-al-2008-dataset.html#run-sampler"><i class="fa fa-check"></i><b>3.2.2</b> Running the sampler</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="example-2-single-threshold-parameter.html"><a href="example-2-single-threshold-parameter.html"><i class="fa fa-check"></i><b>4</b> Example 2 - Single threshold parameter</a></li>
<li class="chapter" data-level="5" data-path="example-3-wagenmakers-2008-experiment-2.html"><a href="example-3-wagenmakers-2008-experiment-2.html"><i class="fa fa-check"></i><b>5</b> Example 3 - Wagenmakers (2008) Experiment 2</a></li>
<li class="chapter" data-level="6" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html"><i class="fa fa-check"></i><b>6</b> Common Problems (Better name required) Troubleshooting page</a><ul>
<li class="chapter" data-level="6.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#how-to-write-a-log-likelihood-function"><i class="fa fa-check"></i><b>6.1</b> How to write a log likelihood function</a><ul>
<li class="chapter" data-level="6.1.1" data-path="common-problems-better-name-required-troubleshooting-page.html"><a href="common-problems-better-name-required-troubleshooting-page.html#writing-your-log-likelihood-function-tips-errors-and-check-list"><i class="fa fa-check"></i><b>6.1.1</b> Writing your log likelihood function: Tips, errors and check list</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-rtchoice-example.html"><a href="non-rtchoice-example.html"><i class="fa fa-check"></i><b>7</b> Non RT/Choice example</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://newcastlecl.org/" target="blank">Published by Newcastle Cognition Lab</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Particle Based Samplers for MCMC</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="how-to-use-the-pmwg-sampler---signal-detection-theory" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> How to use the PMwG sampler - Signal Detection Theory</h1>
<p>Here we demonstrate how to use the PMwG sampler package to run a simple signal detection theory (SDT) analysis on a lexical decision task. We recognise that it is unnecessary to use the sampler package for a simple analysis such as this; however, we hope this example demonstrates the usefulness of the PMwG sampler package.</p>
<div id="sdtOutline" class="section level3">
<h3><span class="header-section-number">2.0.1</span> Signal Detection Theory analysis of lexical decision task</h3>
<p>We assume you have an understanding of SDT and lexical decision tasks, so we’ll jump straight into how you can use the PMwG package with SDT in the context of the lexical decision task.<br></p>
<p><b> Do we need to explain lexical decision tasks?? We desribe the procedure briefly below - Participants were asked to indicate whether a letter string was a <i>word</i> or a <i>non-word</i>. </b></p>
We begin with the distributions for <i>non-word</i> and <i>word</i> stimuli. You can think of these two distributions as the ‘noise’ and ‘signal’ curves, respectively. Each distribution represents the evidence for ‘word-likeness’ and they are assumed to be normally distributed. The <i>non-word</i> distribution (or the ‘noise’ distribution) has a mean (<span class="math inline">\(\mu\)</span>) of 0 and a standard deviation (SD) of 1. We could estimate SD here, but we will use 1 in this example for simplicity. The mean for the <i>word</i> distribution is unknown at this point; however, we assign a d-prime (d’) parameter to denote the difference between the mean of the <i>non-word</i> and the mean of the <i>word</i> distributions (i.e. the ‘sensitivity’ to word stimuli or the signal-noise difference between <i>words</i> and <i>non-word</i>). As can be seen in Figure <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT1">2.1</a>, the <i>word</i> distribution mean is greater than the <i>non-word</i> distribution mean (<b>in the positive direction?</b>); however, the distributions partially overlap where <i>non-words</i> and <i>words</i> are difficult to classify. <br>
<div class="figure"><span id="fig:SDT1"></span>
<img src="SDT_1.png" alt="Simple SDT example of lexical decision task" width="100%" />
<p class="caption">
Figure 2.1: Simple SDT example of lexical decision task
</p>
</div>
<p>The second parameter we denote is the criterion (<b>C</b>) parameter. The criterion is the point at which an individual responds <i>non-word</i> (to the left of <b>C</b> in Figure <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a>) or <i>word</i> (to the right of <b>C</b> in Figure <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a>) and it is set somewhere between the means of the two distributions. If you’re biased to respond <i>word</i>, the criterion would move to the left. Conversely, if you’re biased to respond <i>non-word</i> then the criterion would move to the right.</p>
<div class="figure"><span id="fig:SDT2"></span>
<img src="SDT_2.png" alt="Simple SDT example of lexical decision task" width="100%" />
<p class="caption">
Figure 2.2: Simple SDT example of lexical decision task
</p>
</div>
<p><b> Do we need to add something about means should be positive - to the right of NW mean of 0, otherwise the line about “given these parameters, one would expect that the <i>word</i> distribution would have a higher mean than the non-words, with partial overlap” does not make sense.</b></p>
</div>
<div id="writing-a-log-likelihood-function" class="section level3">
<h3><span class="header-section-number">2.0.2</span> Writing a log-likelihood function</h3>
<p>Let’s write a simple log likelihood function for a fabricated data set. You can copy the code below to follow along with the example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resp &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;word&quot;</span>, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;non-word&quot;</span>)
stim &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;word&quot;</span>, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;non-word&quot;</span>, <span class="st">&quot;word&quot;</span>)
fabData &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">cbind</span>(resp, stim))</code></pre></div>
<p>First we create our fabricated dataset by combining a response <code>resp</code> and a stimulus <code>stim</code> vector into a data frame as shown in <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#tab:fakeHead">2.1</a> below.</p>
<table>
<caption><span id="tab:fakeHead">Table 2.1: </span>A fabricated dataset of 7 trials with a response and a stimuls column</caption>
<thead>
<tr class="header">
<th align="left">resp</th>
<th align="left">stim</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">word</td>
<td align="left">word</td>
</tr>
<tr class="even">
<td align="left">word</td>
<td align="left">word</td>
</tr>
<tr class="odd">
<td align="left">non-word</td>
<td align="left">non-word</td>
</tr>
<tr class="even">
<td align="left">word</td>
<td align="left">word</td>
</tr>
<tr class="odd">
<td align="left">non-word</td>
<td align="left">non-word</td>
</tr>
<tr class="even">
<td align="left">non-word</td>
<td align="left">non-word</td>
</tr>
<tr class="odd">
<td align="left">word</td>
<td align="left">non-word</td>
</tr>
<tr class="even">
<td align="left">non-word</td>
<td align="left">word</td>
</tr>
</tbody>
</table>
<p>Our log likelihood function will step through the data, line by line, and find a likelihood value for each trial, under two parameters; d-prime <code>d</code> and criterion <code>C</code>.</p>
<p><br><b> Remove this paragraph? Some info is covered above</b> As mentioned <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#sdtOutline">above</a> the <i>non-word</i> distribution has a mean of 0 and SD of 1. This then gives a reference point for where the mean of the <i>word</i> distribution would sit and is denoted by d’. Now we must find the location of the criterion. Setting the criterion allows us to determine which response will be made i.e. above the criterion, participant will respond <i>word</i> and below the criterion, participant will respond <i>non-word</i>.</p>
<p>Here is our complete log likelihood function. We have omitted some code from the code blocks below to enhance apperance, so we encourage you to copy the log likelihood function from the following code block if you’d like to follow along with our example.</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">SDT_loglike &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>){
  <span class="cf">if</span> (sample){
    data<span class="op">$</span>response &lt;-<span class="st"> </span><span class="ot">NA</span>
  } <span class="cf">else</span>{
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
    data<span class="op">$</span>out &lt;-<span class="st"> </span><span class="ot">NA</span>
  }
  <span class="cf">if</span> (<span class="op">!</span>sample){
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)){
    <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                        <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
      }<span class="cf">else</span>{
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                        <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
      }
    }<span class="cf">else</span>{
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                        <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
      }<span class="cf">else</span>{
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                        <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }
  }
  <span class="kw">sum</span>(out)
  }
}</code></pre></td></tr></table></div>
<p>We initialise the log likelihood function with three arguments</p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">SDT_loglike &lt;-<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample =</span> <span class="ot">FALSE</span>) {</code></pre></td></tr></table></div>
<ul>
<li><code>x</code> is a named parameter vector (e.g.<code>pars</code>)</li>
<li><code>data</code> is the dataset</li>
<li><code>sample =</code> sample values (For this simple example, we do not require a <code>sample</code> argument.)</li>
</ul>
<p>The first if statement (line 2) checks if you want to sample, this is used for posterior predictive sampling which we will cover in later chapters. and assigns NAs to your data frames response column. If you’re not sampling (like us in this example), you need to create an output vector <code>out</code>. The <code>out</code> vector will contain the log likelihood value for each row/trial in your dataset. <b> Need to explain the <code>(sample)</code> part below </b></p>
<div class="sourceCode" startFrom="2"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>2
3
4
5
6
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (sample){
    data<span class="op">$</span>response &lt;-<span class="st"> </span><span class="ot">NA</span>
    }<span class="cf">else</span>{
      out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
      }</code></pre></td></tr></table></div>
<p>From line 9, we check each row in the data set, first considering all trials with <i>word</i> stimuli <code>if (stim[i] == &quot;word&quot;</code> (line 10), and assign a likelihood for responding <i>word</i> (line 11-12) or <i>non-word</i> (line 13-14). The <i>word</i> distribution has a mean of <code>x[&quot;d&quot;]</code> (d-prime parameter) and a decision criterion parameter <code>x[&quot;C&quot;]</code>. If the response is <i>word</i>, we are considering values ABOVE or to the right of <B>C</B> in <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a>, so we set <code>lower.tail =</code> to <code>FALSE</code>. If the response is <i>non-word</i>, we look for values BELOW or to the left of <B>C</B> in <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a> and we set <code>lower.tail =</code> to <code>TRUE</code>. The <code>log.p =</code> argument takes the log of all likelihood values when set to <code>TRUE</code>. We do this so we can sum all likelihoods at the end of the log likelihood function. <b> Do we need to explain p-norm??</b></p>
<div class="sourceCode" startFrom="8"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>8
9
10
11
12
13
14
15
16
17
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">  <span class="cf">if</span> (<span class="op">!</span>sample){
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)){
      <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
          out[i]&lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
    }<span class="cf">else</span>{
      out[i]&lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                     <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
      }</code></pre></td></tr></table></div>
<p>From the else statement on line 18, we have the function for <i>non-word</i> trials i.e. <code>stim[i] == &quot;non-word&quot;</code>. As can be seen below, the output value <code>out[i]</code> for these trials is arrived at in a similar manner to the <i>word</i> trials. We set the <code>mean</code> to 0 and the standard deviation <code>sd</code> to 1. If the response is <i>word</i>, we are considering values ABOVE or to the right of <B>C</B> in <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a>, so we set <code>lower.tail =</code> to <code>FALSE</code>. If the response is <i>non-word</i>, we look for values BELOW or to the left of <B>C</B> in <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT2">2.2</a> and we set <code>lower.tail =</code> to <code>TRUE</code>. Again we want the log of all likelihood values so <code>log.p = TRUE</code>.</p>
<div class="sourceCode" startFrom="18"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>18
19
20
21
22
23
24
25
26
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">    <span class="cf">else</span>{
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;word&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                        <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i]&lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }</code></pre></td></tr></table></div>
<p>The final line of code on line 24 sums the <code>out</code> vector and returns a log-likelihood value for your model. <b> The text alignment/justification for code blocks is determined by the length of the longest line in the code block</b></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(out)</code></pre></div>
</div>
<div id="testing-the-sdt-log-likelihood-function" class="section level2">
<h2><span class="header-section-number">2.1</span> Testing the SDT log likelihood function</h2>
<p>Before we run the log likelihood function, we must create a parameter vector <code>pars</code> containing the same parameter names used in our log likelihood function above i.e. we name the criterion <code>C</code> and d-prime parameter <code>d</code> and we assign arbitrary values to each parameter. <b> Can this code be improved/shortened?</b></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.8</span>, <span class="dv">2</span>)
<span class="kw">names</span>(pars) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;C&quot;</span>, <span class="st">&quot;d&quot;</span>)</code></pre></div>
<p>We can test run our log likelihood function by passing in the parameter vector <code>pars</code> and the fabricated dataset we created above <code>fabData</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">SDT_loglike</span>(pars, fabData)</code></pre></div>
<pre><code>## [1] -4.795029</code></pre>
<p>Now, if we change the parameter values, the log-likelihood value should also change.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pars &lt;-<span class="st"> </span><span class="kw">replace</span>(pars, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">1.2</span>))
<span class="kw">SDT_loglike</span>(pars, fabData)</code></pre></div>
<pre><code>## [1] -4.532791</code></pre>
<p>We can see the log likelihood has changed, so these values are more accurate given the data. <b> This is vague. What’s the point of this? Seems insufficient to look for a change in the LL</b></p>
</div>
<div id="sdt-log-likelihood-function-for-wagenmakers-experiment" class="section level2">
<h2><span class="header-section-number">2.2</span> SDT log likelihood function for Wagenmakers experiment</h2>
<p>Now that we’ve covered a simple test example, let’s create a log likelihood function for the <span class="citation">Wagenmakers et al. (<a href="#ref-wagenmakers2008diffusion">2008</a>)</span> dataset. Before we do that, we need to cover the design of Wagenmakerssss study.</p>
<div id="description-of-wagenmakers-experiment" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Description of Wagenmakers experiment</h3>
<p>Participants were asked to indicate whether a letter string was a <i>word</i> or a <i>non-word</i>. A subset of Wagenmaker et al data are shown in table <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#tab:wagenmakers10">2.2</a>, with each line representing a single trial. We have a <code>subject</code> column with a subject id (1-19), a condition column <code>cond</code> which indicates the proportion of <i>words</i> to <i>non-words</i> presented within a block of trials. In word blocks (<code>cond = w</code>) participants completed 75% word and 25% non-word trials and for non-word (<code>cond = nw</code>) blocks 75% non-word and 25% word trials. The <code>stim</code> column lists the word’s frequency i.e. is the stimulus a <i>very low frequency</i> word (<code>cond = vlf</code>), a <i>low frequency</i> word (<code>cond = lf</code>) or a <i>high frequency</i> word (<code>cond = hf</code>). The third column <code>resp</code> refers to the participant’s response i.e. the participant responded <i>word</i> (<code>resp = W</code>) or <i>non-word</i> (<code>resp = NW</code>). The two remaining columns list the response time (<code>rt</code>) and whether the paricipant made a correct (<code>correct = 2</code>) or incorrect (<code>correct = 1</code>) choice.</p>
<p>For more details about the experiment please see <a href="https://www.sciencedirect.com/science/article/pii/S0749596X07000496">the original paper</a>. <b> Is this the correct paper to reference? I have changed the name of the columns in the wagenmakers dataset to the names used in the table shown below.</b></p>
<table>
<caption><span id="tab:wagenmakers10">Table 2.2: </span>Subset of 10 trials from the Wagenmakers (2008) dataset.</caption>
<thead>
<tr class="header">
<th align="right">subject</th>
<th align="left">cond</th>
<th align="left">stim</th>
<th align="left">resp</th>
<th align="right">rt</th>
<th align="right">correct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">lf</td>
<td align="left">W</td>
<td align="right">0.410</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">hf</td>
<td align="left">W</td>
<td align="right">0.426</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">nw</td>
<td align="left">NW</td>
<td align="right">0.499</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">lf</td>
<td align="left">W</td>
<td align="right">0.392</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">vlf</td>
<td align="left">W</td>
<td align="right">0.435</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">w</td>
<td align="left">hf</td>
<td align="left">W</td>
<td align="right">0.376</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">lf</td>
<td align="left">W</td>
<td align="right">0.861</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">hf</td>
<td align="left">W</td>
<td align="right">0.563</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">nw</td>
<td align="left">NW</td>
<td align="right">0.666</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">nw</td>
<td align="left">NW</td>
<td align="right">1.561</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">nw</td>
<td align="left">NW</td>
<td align="right">0.503</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">nw</td>
<td align="left">nw</td>
<td align="left">NW</td>
<td align="right">0.445</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>Our log-likelihood function for Wagenmakers experimental data is similar to the function we wrote above, except now we require a criterion parameter for each condition and a d-prime parameter for each of the <code>stim</code> <i>word</i> types. This is illustrated in figure <a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:SDT3">2.3</a> below, where we have a non-word criterion <B>C<sub>nw</sub></B>, a word criterion <B>C<sub>w</sub></B> and three distributions for each of the <code>stim</code> types with corresponding d-prime for each distribution: <b>d<sub>vlf</sub></b>, <b>d<sub>lf</sub></b>, <b>d<sub>hf</sub></b>.</p>
<div class="figure"><span id="fig:SDT3"></span>
<img src="SDT_3.png" alt="Signal detection theory example of lexical decision task" width="100%" />
<p class="caption">
Figure 2.3: Signal detection theory example of lexical decision task
</p>
</div>
<p>Here is our complete log likelihood function for the Wagenmakers data set. <b> Remove SLOW part of ll function?</b></p>
<div class="sourceCode"><table class="sourceCode r numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
</pre></td><td class="sourceCode"><pre><code class="sourceCode r">SDT_loglike_slow =<span class="st"> </span><span class="cf">function</span>(x, data, <span class="dt">sample=</span><span class="ot">FALSE</span>){
  <span class="cf">if</span> (sample){
    data<span class="op">$</span>response &lt;-<span class="st"> </span><span class="ot">NA</span>
  } <span class="cf">else</span>{
    out &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">nrow</span>(data))
  }
  <span class="cf">if</span> (<span class="op">!</span>sample){
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)){
    <span class="cf">if</span> (cond[i] <span class="op">==</span><span class="st"> &quot;w&quot;</span>){
    <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;hf&quot;</span>){
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;HF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
      }<span class="cf">else</span>{
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;HF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
      }
    } <span class="cf">else</span> <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;lf&quot;</span>){
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;LF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
      }<span class="cf">else</span>{
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;LF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      } <span class="cf">else</span> <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;vlf&quot;</span>){
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;VLF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;VLF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>,
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
          }
        }
    <span class="cf">else</span>{
      <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
      }<span class="cf">else</span>{
        out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.w&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>,
                       <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }
    }
    <span class="cf">else</span>{
      <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;hf&quot;</span>){
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;HF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;HF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }  <span class="cf">else</span> <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;lf&quot;</span>){
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;LF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;LF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      } <span class="cf">else</span> <span class="cf">if</span> (stim[i] <span class="op">==</span><span class="st"> &quot;vlf&quot;</span>){
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;VLF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> x[<span class="st">&quot;VLF.d&quot;</span>], <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }
      <span class="cf">else</span>{
        <span class="cf">if</span> (resp[i] <span class="op">==</span><span class="st"> &quot;W&quot;</span>){
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)
        }<span class="cf">else</span>{
          out[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x[<span class="st">&quot;C.nw&quot;</span>], <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>, 
                         <span class="dt">log.p =</span> <span class="ot">TRUE</span>, <span class="dt">lower.tail =</span> <span class="ot">TRUE</span>)
        }
      }
    }
  }
  <span class="kw">sum</span>(out)
  }
}</code></pre></td></tr></table></div>
<p>Line 1 through to line 8 are the same as the log likelihood we wrote for the fabricated dataset above. From line 9, we calculate the log-likelihood <code>out[i]</code> for <i>word</i> condition trials <code>cond[i] == &quot;w&quot;</code> when the stimulus is a high frequency word <code>stim[i] == &quot;hf&quot;</code> for word response <code>resp[i] == &quot;W&quot;</code>. This is done by considering the upper end of the distribution <code>lower.tail = FALSE</code> of the distribution from the word criterion</p>
<p>Again, notice below that we find the upper tail when looking at “word” responses (ie the probability that we are responding word) and lower tail when looking at “non-word” responses. We look at these probabilities given the criterion - which in this scenario is the criterion for the condition where there is a higher proportion of words.</p>
<p>NOTE: we use log.p=TRUE to log scale these values to make for an easy summation after these have been calculated.</p>
<p><a href="how-to-use-the-pmwg-sampler-signal-detection-theory.html#fig:sdtPlot">2.4</a></p>
<div class="figure"><span id="fig:sdtPlot"></span>
<img src="bookdown-demo_files/figure-html/sdtPlot-1.png" alt="sdt posterior" width="672" />
<p class="caption">
Figure 2.4: sdt posterior
</p>
</div>
<p><b>A second example might cover another SDT example with the addition of trial level covariate i.e. analytic solution NA.</b></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-wagenmakers2008diffusion">
<p>Wagenmakers, Eric-Jan, Roger Ratcliff, Pablo Gomez, and Gail McKoon. 2008. “A Diffusion Model Account of Criterion Shifts in the Lexical Decision Task.” <em>Journal of Memory and Language</em> 58 (1). Elsevier: 140–59.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="example-2-forstmann-et-al-2008-dataset.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-SDTExample1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
