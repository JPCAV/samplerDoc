# Troubleshooting PMwG errors {#troubleshoot}

## How to write a log-likelihood function

* What key elements are required in a log-likelihood function to be used in the sampler
* Show comparison times for slow LL and fast LL
* Check list for commmon errors - brief list check this, check that etc.



### Writing your log-likelihood function: Tips, errors and check list



<b>1. The parameter specified does not exist</b>

The parameter name is not specified to be estimated i.e. it is not in the parameter names argument or it is misspelled. Make sure `pars` vector contains the same parameter names you have included in your log-likelihood function and it is the same length. Do not rely on the log likelihood function to throw an error in this case. 
 (e.g.`x[‘b’]`)
 
 
<b>2. All non-continuous data frame variables must be a</b> `factor`.


Data frame variables should be [`factors`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/factor) unless the variable is a continuous variable e.g. response time.
If you pass [`character`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/character) variables to `if` statements and/or `for` loops in your log likelihood function, errors will not occur, however, your log likelihood estimate will be incorrect. For example, 
avoid using character strings like `data$condition == “easy”`. If you must use a character string, be sure to convert the string to a factor with `as.factor`.


<b>3. Spelling errors or mismatched column name references</b>

Correctly reference data frame column names in your log likelihood function e.g. `data$RT` != `data$rt`.

<b>4. When initialising a vector of parameter values - values are not filling in properly</b>

E.g. When a vector for b for all the values across the data set to be used, but there are NAs filling it somewhere.

<b>5. Make sure operations are done on the right scale.</b>


<b>6. Data frame variables are scaled appropriately for the model</b>

Check your variables are correctly scaled and in the correct units. For example, with the LBA, response times must be in seconds rather than milliseconds.

<b>7. The log-likelihood is printed/outputted at the end of function</b>

Make sure your log-likelihood function prints an estimate at the end of the function and the estimate is correctly obtained e.g. sum the log-likelihood estimates for all trials/rows. 
 
<b>8. Sampling error occurs</b>

When sampling, the generated columns are not outputted
 
<b>9. When executing functions row by row (i.e. trial-wise), index MUST be included</b>

If writing a trial-wise/row-wise function (e.g. `if` statement, `for` loop), index `i` must be specified.
```{r twfIndex, echo=TRUE, eval=FALSE}
if (data$condition == “easy”)     # Incorrect reference when iterating over variable
if (data$condition[i] == “easy”)  # Include i index
```

<b>10. Changing parameter values changes the log-likelihood estimate</b>

A simple check to run on your log-likelihood function is to modify your parameter values and observe the change to log-likelihood estimate. Then check if changing parameter values which rely on conditions actually change the log-likelihood estimate.

<b>11. Make sure you have the latest version of the PMwG Samplers package</b>

checkVersion(“pmwg”)


<b>12. Number of iterations for 'burn-in` stage of sampler.</b>

We suggest running `burn-in` for few iterations and particles first. This will give you a sense of a) whether the sampler is working as intended (see troubleshooting/checks for what parameter chains should look like), b) the number of iterations & particles needed to achieve the target acceptance rate, as well as the appropriate epsilon value. The acceptance rate is generally very high for the first few iterations ( > 100) and then declines. After the initial short run, you can check and  optimise the number of particles to be used (and balance with epsilon), so the acceptance rate is close to 30% on a longer, full run. We recommend you start with epsilon = .5 to increase efficiency, then adjust as needed. 

<b>NOTE:</b> Overall, we aim for ~30% acceptance rate of particles. High acceptance rates may be inaccurate if burn-in runs for few iterations. Low acceptance rates are inefficient and may fail to create an efficient distribution for the sampling stage.  


## Appendices

### Wagenmakers SDT script {#wagSDTscript}

A zipped folder containing the dataset from @wagenmakers2008diffusion can be found at this [link](https://www.ejwagenmakers.com/Code/2008/LexDecData.zip). As shown in our script below, the data is stored in the `"PropData.txt"` file.

```{r, WagSDTscript, eval=FALSE}
#~~~~~~~~~~~~~~~~~~~~ Wagenmakers 2008 Lexical decision task ~~~~~~~~~~~~~~~~~~~~~~~~~~~#

# 1) subject = participant number
# 2) block = block number
# 3) practice = 1 if practice block, otherwise 0
# 4) cond = condition either "2" for 75% words or "1" for 75% nonwords)
# 5) stimulus = unique identifier of stimulus, stimuli are nested in frequency conditions
# 6) freq = Code "1" means "high frequency word", code "2" means "low frequency word",
#    and code "3" means "very low frequency word". Codes 4, 5, and 6 = "nonword".
# 7) resp =  0 is nonword, 1 is word, -1 is not interpretable response (i.e., pushed a button,
#         but not the right one and also not the one next to the right button)
# 8) rt = response time in seconds
# 9) censor = 1 if value is eliminated from further analysis;
#       practice block, uninterpretable response, too fast response (<180 ms), too slow response (>3 sec)

rm(list=ls())
require(tidyverse)

wagenmakers2008 <- read.delim("PropData.txt",
                              header = FALSE)

names(wagenmakers2008) <- c("subject","block","practice","cond","stimulus","freq","resp","rt","censor")

wagenmakers2008 <- wagenmakers2008[wagenmakers2008$censor!=1,-c(3,9)]

wagenmakers2008$subject <- factor(wagenmakers2008$subject)

wagenmakers2008$cond <- factor(wagenmakers2008$cond,
                     labels = c("nw","w"))

wagenmakers2008$stimulus <- wagenmakers2008$freq < 4

wagenmakers2008$stimulus <- factor(wagenmakers2008$stimulus,
                     labels = c("nw", "w"))

wagenmakers2008$resp <- factor(wagenmakers2008$resp,
                     labels = c("NW","W"))

wagenmakers2008$freq <- ((wagenmakers2008$freq-1) %% 3)+1

wagenmakers2008$freq <- factor(wagenmakers2008$freq,
                  labels = c("hf","lf","vlf"))

wagenmakers2008$correct <- toupper(wagenmakers2008$stimulus) == toupper(wagenmakers2008$resp)

wagenmakers2008$W <- as.character(wagenmakers2008$freq)

wagenmakers2008$W[wagenmakers2008$stimulus =="nw"] <- "nw"

wagenmakers2008$W <- factor(wagenmakers2008$W,
                  c("hf","lf","vlf","nw"))

wagenmakers2008 <- select(.data = wagenmakers2008, subject, cond, W, resp, rt, correct) %>%
  rename(stimulus = W)

wagenmakers2008$correct <- if_else(wagenmakers2008$correct,
                                   true = "2",
                                   false = "1")
save(wagenmakers2008,
     file = "wagenmakers2008.RData")
```

